{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b2aded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching videos from https://www.youtube.com/@DilmahRealTea/videos...\n",
      "Success! 1685 video links saved to 'dilmah_videos.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Extract youtube video link from youtube channel\n",
    "import yt_dlp\n",
    "import csv\n",
    "\n",
    "def save_channel_videos_to_file(channel_url, filename=\"dilmah_videos.csv\"):\n",
    "    # Configure options for yt-dlp\n",
    "    ydl_opts = {\n",
    "        'quiet': True,\n",
    "        'extract_flat': True,\n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        try:\n",
    "            print(f\"Fetching videos from {channel_url}...\")\n",
    "            result = ydl.extract_info(channel_url, download=False)\n",
    "\n",
    "            if 'entries' in result:\n",
    "                # Open a new CSV file to write the data\n",
    "                with open(filename, mode='w', newline='', encoding='utf-8') as file:\n",
    "                    writer = csv.writer(file)\n",
    "                    # Write the header row\n",
    "                    writer.writerow([\"Video Title\", \"Video URL\"])\n",
    "                    \n",
    "                    count = 0\n",
    "                    for entry in result['entries']:\n",
    "                        video_url = f\"https://www.youtube.com/watch?v={entry['id']}\"\n",
    "                        video_title = entry.get('title', 'No Title')\n",
    "                        \n",
    "                        # Write the data row\n",
    "                        writer.writerow([video_title, video_url])\n",
    "                        count += 1\n",
    "                \n",
    "                print(f\"Success! {count} video links saved to '{filename}'.\")\n",
    "            else:\n",
    "                print(\"No videos found.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Target Channel and run\n",
    "target_url = \"https://www.youtube.com/@DilmahRealTea/videos\"\n",
    "# save_channel_videos_to_file(target_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0c1ef6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting audio...\n",
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=cnuSE24ECuM\n",
      "[youtube] cnuSE24ECuM: Downloading webpage\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] No supported JavaScript runtime could be found. Only deno is enabled by default; to use another runtime add  --js-runtimes RUNTIME[:PATH]  to your command/config. YouTube extraction without a JS runtime has been deprecated, and some formats may be missing. See  https://github.com/yt-dlp/yt-dlp/wiki/EJS  for details on installing one\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] cnuSE24ECuM: Downloading android sdkless player API JSON\n",
      "[youtube] cnuSE24ECuM: Downloading web safari player API JSON\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] cnuSE24ECuM: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] cnuSE24ECuM: Downloading m3u8 information\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] cnuSE24ECuM: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] cnuSE24ECuM: Downloading 1 format(s): 251-12\n",
      "[download] Destination: Blessed Christmas Wishes from the Dilmah Family 2025.webm\n",
      "[download] 100% of    2.09MiB in 00:00:00 at 2.11MiB/s   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
     ]
    }
   ],
   "source": [
    "# Dowload a audio from a youtube video link\n",
    "import yt_dlp\n",
    "\n",
    "def download_youtube_audio(url):\n",
    "    ydl_opts = {\n",
    "        'format': 'bestaudio/best',  # Selects the best audio quality\n",
    "        'postprocessors': [{\n",
    "            'key': 'FFmpegExtractAudio', # Uses FFmpeg to extract audio\n",
    "            'preferredcodec': 'mp3',      # Convert to mp3\n",
    "            'preferredquality': '192',    # Audio bitrate\n",
    "        }],\n",
    "        'outtmpl': '%(title)s.%(ext)s',  # Save file as \"Title.mp3\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            print(\"Extracting audio...\")\n",
    "            ydl.download([url])\n",
    "            print(\"\\nAudio download complete!\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Usage\n",
    "video_url = \"https://www.youtube.com/watch?v=cnuSE24ECuM\"\n",
    "download_youtube_audio(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d289b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hello friends, as we celebrate Christmas, things that are happening in the world around us demand reflection on what truly matters. Values, purpose and how we can positively impact people and nature. Our grandfather wanted to make the world a better tea and by better he meant kinder, better for our health, better for nature and better tasting. He meant it sincerely, which is why Dilma has a foundation of quality and integrity with a heart of kindness. My father's dream became reality 40 years ago. It has now become the global mission for the family to touch the lives of hundreds of thousands of less fortunate people every year through our work in tea, tourism and cinnamon. Business must serve humanity. Life without purpose is meaningless. So for us this blessed season is as much about hope as it is about giving. We cannot live without hope. Yet conflict chaos and inequality around the world are pushing many towards hopelessness The coolest thing about all this is that the happiness the strength the resilience we all seek comes more easily from giving than from receiving It's the truth, something we learned from our grandfather's legacy of kindness. We're a family business. We believe in the transformative power of tea. Every cup presents our respect for nature and our generational commitment to quality, integrity and purpose. It's you, our customers around the world, that help us to translate that purpose into impact. True joy comes from giving. Ours is a powerful partnership in giving and receiving. Every cup, a cup of kindness. Taste and goodness with the assurance of kindness. From us all. Merry Christmas! and a happy 2026.\n"
     ]
    }
   ],
   "source": [
    "# get transcript from youtube audio\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from groq import Groq\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "filename = \"Blessed Christmas Wishes from the Dilmah Family 2025.webm\"\n",
    "\n",
    "with open(filename, \"rb\") as file:\n",
    "    transcription = client.audio.transcriptions.create(\n",
    "      file=(filename, file.read()),\n",
    "      model=\"whisper-large-v3-turbo\",\n",
    "      temperature=0,\n",
    "      response_format=\"verbose_json\",\n",
    "    )\n",
    "    print(transcription.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607ad181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered file saved as: dilmah_videos_transcription_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "# filter the csv file to get only the successful transcriptions\n",
    "import pandas as pd\n",
    "\n",
    "# Input and output file paths\n",
    "input_file = \"dilmah_videos_transcription.csv\"\n",
    "output_file = \"dilmah_videos_transcription_filtered.csv\"\n",
    "\n",
    "# Read the CSV\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Filter rows where Status is 'Success'\n",
    "df_success = df[df[\"Status\"] == \"Success\"]\n",
    "\n",
    "# Save to a new CSV (without index column)\n",
    "df_success.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Filtered file saved as: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f284d6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize the transcript for RAG indexing\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "import time\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "client = Groq(api_key=os.getenv(\"GROQ_API_KEY\"))\n",
    "\n",
    "INPUT_CSV = \"dilmah_videos_transcription_part_6.csv\"\n",
    "OUTPUT_CSV = \"data_rag_ready.csv\"\n",
    "\n",
    "RAG_PROMPT = \"\"\"\n",
    "You are preparing content for a Retrieval-Augmented Generation (RAG) system.\n",
    "\n",
    "Task:\n",
    "Create a dense, factual summary of the transcript optimized for semantic retrieval.\n",
    "\n",
    "Rules:\n",
    "- Preserve key entities (people, brands, organizations, locations)\n",
    "- Preserve facts, dates, numbers, milestones\n",
    "- Remove filler, greetings, repetition, and emotional language\n",
    "- Do NOT add new information\n",
    "- Do NOT use marketing language\n",
    "- Use neutral, information-dense sentences\n",
    "- 3–5 sentences maximum\n",
    "\n",
    "Transcript:\n",
    "{transcript}\n",
    "\"\"\"\n",
    "\n",
    "def summarize_for_rag(transcript):\n",
    "    if not isinstance(transcript, str) or transcript.strip() == \"\":\n",
    "        return \"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"openai/gpt-oss-120b\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You summarize transcripts for RAG indexing.\"},\n",
    "            {\"role\": \"user\", \"content\": RAG_PROMPT.format(transcript=transcript)}\n",
    "        ],\n",
    "        temperature=0.2,\n",
    "        max_completion_tokens=400,\n",
    "        top_p=1,\n",
    "        reasoning_effort=\"medium\"\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "    rag_summaries = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        print(f\"Processing {idx + 1}/{len(df)}\")\n",
    "\n",
    "        if row.get(\"Status\") != \"Success\":\n",
    "            rag_summaries.append(\"\")\n",
    "            continue\n",
    "\n",
    "        summary = summarize_for_rag(row[\"Transcript\"])\n",
    "        rag_summaries.append(summary)\n",
    "\n",
    "        # Gentle rate limiting\n",
    "        time.sleep(1)\n",
    "\n",
    "    df[\"Summary\"] = rag_summaries\n",
    "    df.to_csv(OUTPUT_CSV, index=False)\n",
    "\n",
    "    print(f\"\\n✅ RAG-ready CSV saved as: {OUTPUT_CSV}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280d8c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572f41e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10ef984",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Google ADK Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
