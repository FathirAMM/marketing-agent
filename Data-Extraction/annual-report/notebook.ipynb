{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee04a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU required: True\n",
    "# curl -fsSL https://ollama.com/install.sh | sh\n",
    "# ollama pull deepseek-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9964ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -q pymupdf ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee2df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pdf into high-quality images and save them with page numbers\n",
    "\n",
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, output_folder=\"dilmah_report_images\"):\n",
    "    \"\"\"\n",
    "    Converts a PDF into high-quality images and saves them with page numbers.\n",
    "    \"\"\"\n",
    "    # 1. Create the output directory\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        print(f\"Created folder: {output_folder}\")\n",
    "\n",
    "    # 2. Open the PDF\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "        print(f\"Processing: {pdf_path} ({len(doc)} pages)\")\n",
    "    except Exception as e:\n",
    "        return f\"Error opening PDF: {e}\"\n",
    "\n",
    "    image_paths = []\n",
    "\n",
    "    # 3. Iterate through pages\n",
    "    for page_num in range(len(doc)):\n",
    "        page = doc.load_page(page_num)\n",
    "        \n",
    "        # Using 300 DPI (Matrix 300/72 = 4.166) for high-quality OCR input\n",
    "        zoom = 300 / 72\n",
    "        matrix = fitz.Matrix(zoom, zoom)\n",
    "        \n",
    "        # Render page to a pixmap (image)\n",
    "        pix = page.get_pixmap(matrix=matrix, alpha=False)\n",
    "        \n",
    "        # 4. Define filename with page number (1-based indexing)\n",
    "        filename = f\"page_{page_num + 1}.png\"\n",
    "        filepath = os.path.join(output_folder, filename)\n",
    "        \n",
    "        # 5. Save the file\n",
    "        pix.save(filepath)\n",
    "        image_paths.append(filepath)\n",
    "        \n",
    "        if (page_num + 1) % 5 == 0:\n",
    "            print(f\"Done: {page_num + 1} pages...\")\n",
    "\n",
    "    doc.close()\n",
    "    print(f\"\\n‚úÖ Success! {len(image_paths)} images saved in '{output_folder}'\")\n",
    "    return image_paths\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# Ensure you have uploaded \"Annual Report - Dilmah.pdf\" to your Colab files / appropriate directory\n",
    "# pdf_name = \"Annual Report - Dilmah.pdf\"\n",
    "# saved_images = convert_pdf_to_images(pdf_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8976c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- EXECUTION ---\n",
    "# Ensure your images are in the folder from the previous step\n",
    "# Extract text from images using Ollama's DeepSeek-OCR model\n",
    "# This will convert the images into Markdown text files\n",
    "\n",
    "import ollama\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_ollama_ocr(input_folder=\"dilmah_report_images\", output_folder=\"ollama_results\"):\n",
    "    # 1. Get images (sorted by page number)\n",
    "    # Assumes filenames like \"page_1.png\", \"page_2.png\"\n",
    "    image_paths = sorted(\n",
    "        glob.glob(os.path.join(input_folder, \"*.png\")),\n",
    "        key=lambda x: int(os.path.splitext(os.path.basename(x))[0].split('_')[-1])\n",
    "    )\n",
    "    \n",
    "    if not image_paths:\n",
    "        print(f\"‚ùå No images found in {input_folder}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    print(f\"üìù Processing {len(image_paths)} pages with DeepSeek-OCR...\")\n",
    "\n",
    "    # 2. Iterate and process\n",
    "    for img_path in tqdm(image_paths):\n",
    "        try:\n",
    "            # Specific prompt trigger for DeepSeek-OCR to output Markdown\n",
    "            # The model is trained to recognize this specific grounding tag\n",
    "            prompt = \"<|grounding|>Convert the document to markdown.\"\n",
    "            \n",
    "            response = ollama.chat(\n",
    "                model='deepseek-ocr',\n",
    "                messages=[{\n",
    "                    'role': 'user',\n",
    "                    'content': prompt,\n",
    "                    'images': [img_path]\n",
    "                }]\n",
    "            )\n",
    "            \n",
    "            # 3. Save result\n",
    "            extracted_text = response['message']['content']\n",
    "            \n",
    "            base_name = os.path.basename(img_path)\n",
    "            txt_filename = os.path.splitext(base_name)[0] + \".md\"\n",
    "            save_path = os.path.join(output_folder, txt_filename)\n",
    "            \n",
    "            with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(extracted_text)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è Error on {img_path}: {e}\")\n",
    "\n",
    "    print(f\"\\n‚úÖ Done! Markdown files saved in '{output_folder}'\")\n",
    "\n",
    "# --- EXECUTION ---\n",
    "# Ensure your images are in the folder from the previous step\n",
    "# run_ollama_ocr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65068f57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ee33b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1786166e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463fc78d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
